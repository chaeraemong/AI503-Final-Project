# PFNs
Prior-data Fitted Networks (PFNs, https://arxiv.org/abs/2112.10510) are transformer-based models trained to approximate Bayesian prediction. They are trained to do this via supervised in-context learning on datasets randomly drawn from a prior. Priors can in general be described by a function that samples datasets, or more generally a batch of datasets. The PFN is then trained to predict a hold-out set of labels, given the rest of the dataset.
